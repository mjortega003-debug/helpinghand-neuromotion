# helpinghand-neuromotion
A mind-machine interface system using trained machine learning models to collect user inputs from an ekg and transfer that into robotic movements. For example, someone with an amputated forearm could have nodes placed on their brachial plexus further up the arm and interface with their prosthetic as if it was their own hand, or a construction worker that needs to lift heavy objects repeatedly could have some kind of mechanical brace around his thighs and back that are tied into the movement of those muscles providing more strength. The main basis of this project would be a trained ML model that can decipher the different ekg signals and break them down into intended movement. Ideally this could be done with inexpensive equipment, which would additionally lower costs of the prosthetics for people that need them
